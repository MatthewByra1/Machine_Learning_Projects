{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntroNueralNetworks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLFykEsi702-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np #A mathematics tool we can use to deal with arrays\n",
        "import torch #PyTorch is the machine learning library we will use\n",
        "import torchvision #Gives us access to the dataset we need\n",
        "import matplotlib.pyplot as plt #Plotting tool\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim #Neural Network optimization tool"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl0ai48h94TQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "8a37abeb-b4cb-4df2-8027-50c40996b2d5"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,))])\n",
        "training_set = datasets.MNIST('-/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(training_set, batch_size=64, shuffle=True)\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to -/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 9399111.98it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting -/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to -/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 143484.53it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting -/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to -/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2423341.99it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting -/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to -/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 52360.65it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting -/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv_5tblGJ488",
        "colab_type": "code",
        "outputId": "9a9e7274-b097-4ae2-f1f5-950ccf0ff972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap= \"Greys_r\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcc793a8080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngaAIPxAU4QeCIvxAUIQfCIrwA0H9HaGHdBd8x3VsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f9rTDTOKMuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#784 inputs, 128  hiddenl (ReLU), 64 hidden2 (ReLU), 10 output (Softmax)\n",
        "from torch import nn\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "#Build a Feed-forward network\n",
        "model= nn.Sequential(nn.Linear(input_size, hidden_sizes[0]), nn.ReLU(), nn.Linear(hidden_sizes[0], hidden_sizes[1]), \n",
        "                     nn.Linear(hidden_sizes[1], output_size), nn.Softmax(dim=1))\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "images.resize_(images.shape[0], 1, 784)\n",
        "ps = model.forward(images[0, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J5jEeAK7fBJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62b752d7-87cc-4da6-8e9a-cc420003484a"
      },
      "source": [
        "#define loss function\n",
        "criterion = nn.NLLLoss()\n",
        "#iterate over the data\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "#reshape data\n",
        "images = images.view(images.shape[0], -1)\n",
        "#Feed forward\n",
        "logps = model(images)\n",
        "loss = criterion(logps, labels)\n",
        "print(loss)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-0.0979, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN8ujszPAjP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "eb3c3d71-445e-4caf-e5dd-c83c41223ee7"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "epochs = 4\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        #Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(e, running_loss/len(trainloader))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 -0.9098364996757589\n",
            "1 -0.9100604437307508\n",
            "2 -0.9101923854112117\n",
            "3 -0.9103974499809209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z7yBPhDAkib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df6339a7-802f-4515-bafb-4de32da30d1a"
      },
      "source": [
        "correct = 0\n",
        "all_counted = 0\n",
        "for images,labels in trainloader:\n",
        "  for i in range(len(labels)):\n",
        "    img = images[i].view(1, 784)\n",
        "    with torch.no_grad():\n",
        "        logps = model(img)\n",
        "\n",
        "    \n",
        "    ps = torch.exp(logps)\n",
        "    probability = list(ps.numpy()[0])\n",
        "    pred_label = probability.index(max(probability))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct += 1\n",
        "    all_counted += 1\n",
        "\n",
        "print(\"Model Accuracy =\", (correct/all_counted))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy = 0.9205333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_BkpMm-DvxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model, './recognition_digit_model.pt') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQUnw2N8G8Eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}